# **************************************************************************** #
#                                                                              #
#                                                         :::      ::::::::    #
#    project_structure.txt                              :+:      :+:    :+:    #
#                                                     +:+ +:+         +:+      #
#    By: djuarez <djuarez@student.42.fr>            +#+  +:+       +#+         #
#                                                 +#+#+#+#+#+   +#+            #
#    Created: 2025/05/28 19:18:02 by djuarez           #+#    #+#              #
#    Updated: 2025/07/30 14:09:06 by djuarez          ###   ########.fr        #
#                                                                              #
# **************************************************************************** #

minishell/
├── Makefile
├── main.c
├── include/
│   ├── minishell.h
│   ├── lexer.h
│   ├── parser.h          ← encabezado del parser
│   └── ...otros .h
├── src/
│   ├── lexer/
│   │   ├── tokenizer.c
│   │   └── lexer_utils.c
│   ├── parser/
│   │   ├── parser.c
│   │   ├── parser_utils.c
│   │   ├── parse_cmd.c
│   │   ├── parse_redir.c
│   │   ├── parse_pipe.c
│   │   
│   ├── executor/
│   ├── builtins/
│   ├── signals/
│   └── utils/
├── libft/


quotes 


✅  Paso 1. are_quotes_closed(input)
✅ Ya hecho. Verifica si vale la pena seguir procesando.
✅ Paso 2. extract_quoted_segment(const char *input, int *len)
🔧 Próximo paso.
Extrae "lo que está entre comillas" y devuelve len.
🔷 Paso 3. reconstruct_words(const char *input)
💡 Reemplaza fill_tokens.
Esta será tu nueva función central del lexer:
    Recorre carácter por carácter
    Cuando encuentra comillas → llama a extract_quoted_segment
    Cuando encuentra texto normal → lo acumula
    Si están pegados (""ec"ho") → los concatena
    Separa en tokens[] solo cuando hay un espacio real
Internamente usará:
    is_quote(c)
    extract_quoted_segment
    remove_surrounding_quotes (nueva versión mejorada)
🔷 Paso 4. build_token_list(tokens)
✅ Ya la tienes. No la cambias.
🔷 Paso 5. is_operator(token)
✅ Ya la tienes. Se usa después de obtener tokens.
🔷 Paso 6. clean_input_quotes()
📦 Esta será una función "wrapper" que encapsula todo el flujo y puede ser útil si quieres usarla también desde otras partes del código.
🔷 Paso 7. debug_quotes_status()


🟩 Fase 1 — Ya implementado y válido
Orden	Función	Estado	Rol
1	is_quote	                ✅ Hecha	Detecta ' y "
2	is_operator	                ✅ Hecha	Detecta operadores (`
3	operator_len	            ✅ Hecha	Calcula longitud de operador (>>, <<, etc.)
4	token_len	                ✅ Hecha	Longitud del siguiente token
5	next_token	                ✅ Hecha	Extrae siguiente token
6	count_tokens    	        ✅ Hecha	Cuenta tokens en el input
7	next_token_and_len	        ✅ Hecha	Combina extracción y longitud
8	build_token_list	        ✅ Hecha	Convierte char **tokens a lista t_token *
9	determine_token_type	    ✅ Hecha	Decide el tipo de token (PIPE, WORD, etc.)
10	tokenize_input	            ✅ Hecha	Función principal del lexer
🟨 Fase 2 — Preprocesamiento de quotes (nuevo)
Orden	Función	Estado	Rol
11	are_quotes_closed	        ✅ Hecha	Verifica que las comillas estén bien cerradas
12	extract_quoted_segment	    ✅ A crear	Extrae "contenido" de forma segura
13	remove_surrounding_quotes	🔜 Mejorar	Elimina comillas exteriores correctamente (', ")
14	reconstruct_words	        🔜 A crear	Divide y concatena palabras y bloques entre comillas
15	clean_input_quotes	        🔜 A crear	Función central que coordina todo el manejo de quotes
🧪 Fase 3 — Debug y testing
Orden	Función	Estado	Rol
16	debug_quotes_status	        🔜 Opcional	Imprime resultados para pruebas internas de quotes
17	print_token_list	        ✅ Hecha	Imprime t_token * (ya existente y útil para testing)